## ▣ 예제72. 모델 평가: 이론

## 1. 성능 평가 지표 설명

| 지표 | 설명 |
|------|------|
| 정확도 | 전체 예측 중 올바른 예측의 비율 |
| 카파 통계량 | 우연에 의한 정확도를 보정한 지표 |
| 민감도 | 실제 양성 중 정확히 예측된 비율 |
| 특이도 | 실제 음성 중 정확히 예측된 비율 |
| 정밀도 | 양성 예측 중 실제 양성의 비율 |
| 재현율 | 민감도와 동일 |
| F1-score | 정밀도와 재현율의 조화평균 |

**참고 자료**: [모델 평가 이론](https://cafe.daum.net/oracleoracle/Sotv/818)

---

## 2. 실습: 카파 통계량 계산

### 📌 문제
다음 혼동 행렬에 대한 카파 통계량을 구하시오:

| 실제 \ 예측 | False | True | 합계 |
|------------|-------|------|------|
| False      | 70    | 30   | 100  |
| True       | 40    | 60   | 100  |
| 합계       | 110   | 90   | 200  |

### 💻 코드
```r
# 혼동 행렬 생성
a <- as.table(matrix(c(70, 30, 40, 60), 
                     byrow=TRUE, 
                     nrow=2, 
                     ncol=2))
```

## 3. 머신러닝 모델 평가

### 📌 데이터셋: Wisconsin Breast Cancer Data

#### 단계 1: 데이터 준비
```r
setwd("c:\\data")
wbcd <- read.csv("wisc_bc_data.csv", header=TRUE, stringsAsFactors=FALSE)
```

#### 단계 2: 데이터 정규화 및 분할
```r
# 코드 위치
```

#### 단계 3: KNN 모델링
```r
# 코드 위치
```

#### 단계 4: 성능 평가
| 평가 지표    | 값        |
|-------------|-----------|
| 정확도      | 0.9122807 |
| 카파 통계량 | 0.8224    |
| 민감도      | 0.8148148 |
| 특이도      | 1.0000000 |
| 정밀도      | 1.0000000 |
| 재현율      | 0.8148148 |
| F1-score    | 0.8979592 |

## 4. 독버섯 데이터 분류

### 📌 나이브 베이즈 분류기 적용

#### 단계 1: 데이터 로드
```r
mush <- read.csv("c:\\data\\mushrooms.csv", stringsAsFactors=TRUE)
```

#### 단계 2: 모델링
```r
# 코드 위치
```

#### 단계 3: Laplace 평활화에 따른 성능 비교
| Laplace | 정확도 | 카파 | 민감도 | 특이도 | 정밀도 | 재현율 | F1-score |
|---------|--------|------|--------|--------|--------|--------|-----------|
| 0.0001  |        |      |        |        |        |        |           |
| 0.0002  |        |      |        |        |        |        |           |
| 0.0003  |        |      |        |        |        |        |           |
